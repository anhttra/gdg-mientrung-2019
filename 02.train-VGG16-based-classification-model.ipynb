{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train a classification model based on the (pretrained) VGG16 model.\n",
    "\n",
    "Author: Anh Trung Tra    \n",
    "Email: tratrunganh001@gmail.com\n",
    "\n",
    "**Environment**:\n",
    "- Ubuntu 16.04\n",
    "- Python3.5\n",
    "- TensorFlow 2.0\n",
    "\n",
    "**Refs**:\n",
    "https://www.tensorflow.org/alpha/tutorials/load_data/images  \n",
    "\n",
    "**TODO:**  \n",
    "[X] Build the data pipeline for the train and val set.        \n",
    "[X] Create the classification model based on pretrained VGG16 model.      \n",
    "[X] Train and save the dog/cat prediction model.\n",
    "\n",
    "Updated by: Le Trung Phong - letrungphong95@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let import some things ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "keras = tf.keras\n",
    "\n",
    "print(\"Tensorflow version: {}\".format(tf.__version__))\n",
    "\n",
    "# optional params\n",
    "_IMAGE_SIZE = 224\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the data pipeline for the train and val set, ready for training the model\n",
    "\n",
    "- Train data pipeline:  \n",
    "tfrecord --> Parse --> Augment --> Resize --> Preprocess --> Shuffle --> Batch --> Prefetch\n",
    "- Val data pipeline:  \n",
    "tfrecord --> Parse --> Resize --> Preprocess --> Batch --> Prefetch\n",
    "\n",
    "Ref: \n",
    "https://www.tensorflow.org/alpha/tutorials/load_data/images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary describing the features.  \n",
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "# Helper functions\n",
    "def _parse_function(example_proto):\n",
    "    \"\"\" Parse the data from given `example_proto`. \"\"\"\n",
    "    parsed_example = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "    image_string = parsed_example['image_raw']\n",
    "    label = parsed_example['label']\n",
    "    height = parsed_example['height']\n",
    "    weight = parsed_example['width']\n",
    "    \n",
    "    # Don't use tf.image.decode_image, or the output shape will be undefined\n",
    "    image_decoded = tf.image.decode_jpeg(image_string, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image_decoded, tf.float32) # convert to float values in [0, 1]\n",
    "    \n",
    "    return image, label, height, weight\n",
    "\n",
    "def _augment_image(image, label, height, weight):\n",
    "    \"\"\" Augment image for training.\"\"\"    \n",
    "    image = tf.image.random_flip_left_right(image)        \n",
    "    image = tf.image.random_crop(image, [height, weight, 3])\n",
    "    image = tf.image.random_brightness(image, max_delta=32.0 / 255.0)\n",
    "    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)                \n",
    "    \n",
    "    return image, label, height, weight\n",
    "      \n",
    "def _resize_image(image, label, height, weight, size):\n",
    "    \"\"\" Resize image to meet the input size of the classification model. \"\"\"\n",
    "    resized_image = tf.image.resize_with_pad(image, size, size)   \n",
    "\n",
    "    return resized_image, label\n",
    "\n",
    "def _preprocess_image(image, label):\n",
    "    \"\"\" Preprocess image to meet the VGG16 image preprocessing method.\"\"\"\n",
    "    # scale to [0, 255]\n",
    "    preprocessed_image = 255.0*image\n",
    "    \n",
    "    # convert RGB to BGR\n",
    "    preprocessed_image = preprocessed_image[...,::-1]\n",
    "    \n",
    "    # subtract the mean\n",
    "    preprocessed_image = preprocessed_image - [103.939, 116.779, 123.68]\n",
    "    \n",
    "    return preprocessed_image, label    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((None, 224, 224, 3), (None,)), types: (tf.float32, tf.int64)>\n",
      "<PrefetchDataset shapes: ((None, 224, 224, 3), (None,)), types: (tf.float32, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "# train data pipeline\n",
    "train_dataset = (tf.data.TFRecordDataset('data/PetImages/train.tfrecord')\n",
    "                     .map(_parse_function)\n",
    "                     .map(_augment_image)\n",
    "                     .map(lambda im, l, h, w: _resize_image(im, l, h, w, size=_IMAGE_SIZE))\n",
    "                     .map(_preprocess_image)\n",
    "                     .shuffle(1000)\n",
    "                     .batch(32)\n",
    "                     .prefetch(1)  # make sure you always have one batch ready to serve\n",
    "                )\n",
    "\n",
    "# val data pipeline\n",
    "val_dataset = (tf.data.TFRecordDataset('data/PetImages/val.tfrecord')\n",
    "                     .map(_parse_function)\n",
    "                     .map(lambda im, l, h, w: _resize_image(im, l, h, w, size=_IMAGE_SIZE))\n",
    "                     .map(_preprocess_image)\n",
    "                     .batch(32)\n",
    "                     .prefetch(1)  # make sure you always have one batch ready to serve                \n",
    "              )\n",
    "print(train_dataset)\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the classification model based on pretrained VGG16 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 7, 7, 512)         262656    \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 7, 7, 256)         131328    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 7, 7, 128)         32896     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 15,141,826\n",
      "Trainable params: 15,141,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def model_fn(num_class=None, image_size=None):\n",
    "    \"\"\"\n",
    "    This function creates initiative CNN model using VGG16 convolutional layer \n",
    "    and add some new layer on top to finetune our Dataset.  \n",
    "    \n",
    "    Arguments:\n",
    "    -num_class: int, number of class for output of our model \n",
    "    (E.g: num_class=2 for Cat and Dog dataset)\n",
    "    -image_size: int, size of input image from dataset for our model \n",
    "    \n",
    "    Returns:\n",
    "    - model: keras sequential model class, intiative model from keras   \n",
    "    \"\"\"\n",
    "    # Define keras model \n",
    "    model = keras.models.Sequential()\n",
    "    # Add the vgg16 convolutional base model\n",
    "    model.add(keras.applications.VGG16(weights='imagenet', \n",
    "                                       include_top=False, \n",
    "                                       input_shape=(image_size, image_size, 3)))\n",
    "    # Add new layers on top\n",
    "    model.add(keras.layers.Conv2D(512, 1))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Conv2D(256, 1))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.Conv2D(128, 1))\n",
    "    model.add(keras.layers.Activation('relu'))\n",
    "    model.add(keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(keras.layers.Dense(num_class, activation='softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create initiative model\n",
    "model = model_fn(num_class=2, image_size=_IMAGE_SIZE)\n",
    "\n",
    "# Define model with optimizer method and loss function\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save the dog/cat prediction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 53s 535ms/step - loss: 0.1113 - accuracy: 0.9506\n",
      "Val loss = 0.0610, val acc = 0.9771\n"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=tf.optimizers.Adam(1e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# train the model \n",
    "model.fit_generator(train_dataset, \n",
    "                    epochs=1, \n",
    "                    steps_per_epoch = 100)\n",
    "\n",
    "# Evaluate on the val dataset \n",
    "val_loss, val_acc = model.evaluate_generator(val_dataset)\n",
    "print(\"Val loss = {:.4f}, val acc = {:.4f}\".format(val_loss, val_acc))\n",
    "\n",
    "# Save keras model to .h5 file after training \n",
    "model.save('experiments/VGG16_based_classification/vgg16_catdog.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
